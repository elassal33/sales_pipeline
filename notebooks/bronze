
# Databricks notebook source
from pyspark.sql import SparkSession
import pyspark.sql.functions as F
from pyspark.sql.types import *
from pyspark.sql.window import Window

# COMMAND ----------

# MAGIC %md
# MAGIC ## BRONZE LAYER

# COMMAND ----------

crm_cust_df =  spark.read.format('csv').options(header='true', inferSchema='true')\
 .load('/Volumes/my_files/my_schema/crm/cust_info.csv')
crm_prd_info_df = spark.read.format('csv').options(header='true', inferSchema='true')\
    .load('/Volumes/my_files/my_schema/crm/prd_info.csv')
crm_sales_details_df = spark.read.format('csv').options(header='true', inferSchema='true')\
    .load('/Volumes/my_files/my_schema/crm/sales_details.csv')
erp_LOC_A101_df = spark.read.format('csv').options(header='true', inferSchema='true')\
    .load('/Volumes/my_files/my_schema/erp/LOC_A101.csv')
erp_CUST_AZ12_df = spark.read.format('csv').options(header='true', inferSchema='true')\
    .load('/Volumes/my_files/my_schema/erp/CUST_AZ12.csv')
erp_PX_CAT_G1V2_df = spark.read.format('csv').options(header='true', inferSchema='true')\
    .load('/Volumes/my_files/my_schema/erp/PX_CAT_G1V2.csv')

# COMMAND ----------

crm_cust_df.write.mode("overwrite").format("delta")\
.save("/Volumes/project/bronze/raw_data/crm/crm_cust_df")
crm_prd_info_df.write.mode("overwrite").format("delta")\
.save("/Volumes/project/bronze/raw_data/crm/crm_prd_info")
crm_sales_details_df.write.mode("overwrite").format("delta")\
.save("/Volumes/project/bronze/raw_data/crm/crm_sales_details_df")
erp_LOC_A101_df.write.mode("overwrite").format("delta")\
.save("/Volumes/project/bronze/raw_data/erp/erp_LOC_A101_df")
erp_CUST_AZ12_df.write.mode("overwrite").format("delta")\
.save("/Volumes/project/bronze/raw_data/erp/erp_CUST_AZ12_df")
erp_PX_CAT_G1V2_df.write.mode("overwrite").format("delta")\
.save("/Volumes/project/bronze/raw_data/erp/erp_PX_CAT_G1V2_df")
